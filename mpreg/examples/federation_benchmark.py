#!/usr/bin/env python3
"""
MPREG Federated Pub/Sub Performance Benchmarks

This script provides comprehensive performance testing for the federated
topic exchange system, measuring:
- Cross-cluster routing latency
- Bloom filter efficiency at scale
- Federation overhead
- Scalability characteristics

Usage:
    poetry run python mpreg/examples/federation_benchmark.py
"""

import asyncio
import gc
import sys
import time
from dataclasses import dataclass, field
from typing import Any

# Add the parent directory to Python path for imports
sys.path.insert(0, ".")

from mpreg.core.model import PubSubMessage, PubSubSubscription, TopicPattern
from mpreg.federation import TopicBloomFilter
from mpreg.federation.federated_topic_exchange import (
    FederatedTopicExchange,
    connect_clusters,
    create_federated_cluster,
)

from .topic_exchange_benchmark import BenchmarkRun


@dataclass(slots=True)
class FederationBenchmarkSuite:
    """Comprehensive benchmark suite for federated pub/sub system."""

    results: dict[str, list[dict[str, Any]]] = field(default_factory=dict)
    clusters: dict[str, FederatedTopicExchange] = field(default_factory=dict)

    async def run_all_benchmarks(self):
        """Run the complete federation benchmark suite."""
        print("üåç MPREG Federated Pub/Sub - Performance Benchmarks")
        print("=" * 70)
        print("‚ö° Testing planet-scale federation performance characteristics")
        print(
            "üìä Measuring cross-cluster routing, bloom filter efficiency, and scalability"
        )
        print()

        try:
            # Benchmark 1: Bloom filter performance
            await self.benchmark_bloom_filter_performance()

            # Benchmark 2: Cross-cluster routing latency
            await self.benchmark_cross_cluster_routing()

            # Benchmark 3: Federation scalability
            await self.benchmark_federation_scalability()

            # Benchmark 4: Memory efficiency
            await self.benchmark_federation_memory_efficiency()

            # Benchmark 5: Concurrent federation operations
            await self.benchmark_concurrent_federation()

            # Final analysis
            self._analyze_federation_performance()

        except Exception as e:
            print(f"‚ùå Benchmark suite failed: {e}")
            raise
        finally:
            # Clean up resources
            await self._cleanup_clusters()

        print("\n‚úÖ All federation benchmarks completed successfully!")

    async def benchmark_bloom_filter_performance(self):
        """Test bloom filter performance at various scales."""
        print("üå∏ Benchmark 1: Bloom Filter Performance")
        print("-" * 50)

        test_configs = [
            (100, "Small cluster"),
            (1_000, "Medium cluster"),
            (10_000, "Large cluster"),
            (50_000, "Enterprise cluster"),
            (100_000, "Planet-scale cluster"),
        ]

        bloom_results = []

        for pattern_count, description in test_configs:
            print(
                f"\n  üîç Testing bloom filter with {pattern_count:,} patterns ({description})..."
            )

            # Create bloom filter
            bloom_filter = TopicBloomFilter()

            # Generate realistic patterns
            patterns = self._generate_realistic_patterns(pattern_count)

            # Measure pattern addition performance
            add_start = time.time()
            for pattern in patterns:
                bloom_filter.add_pattern(pattern)
            add_time = time.time() - add_start

            # Measure lookup performance
            test_topics = self._generate_test_topics(1000)

            lookup_benchmark = BenchmarkRun(
                name=f"bloom_lookup_{pattern_count}",
                min_duration_seconds=2.0,
                warmup_iterations=100,
            )

            iteration_counter = [0]  # Use list for closure

            def lookup_operation():
                topic = test_topics[iteration_counter[0] % len(test_topics)]
                result = bloom_filter.might_contain(topic)
                iteration_counter[0] += 1
                return result

            lookup_stats = lookup_benchmark.run_timed_benchmark(lookup_operation)

            # Calculate metrics
            false_positive_rate = bloom_filter.estimated_false_positive_rate()
            memory_usage = len(bloom_filter.bit_array)
            memory_per_pattern = memory_usage / pattern_count

            result = {
                "pattern_count": pattern_count,
                "description": description,
                "add_time_seconds": add_time,
                "patterns_per_second": pattern_count / add_time,
                "lookup_stats": lookup_stats,
                "false_positive_rate": false_positive_rate,
                "memory_bytes": memory_usage,
                "memory_per_pattern_bytes": memory_per_pattern,
                "memory_efficiency": "excellent"
                if memory_per_pattern < 1.0
                else "good"
                if memory_per_pattern < 10.0
                else "poor",
            }

            bloom_results.append(result)

            print(
                f"      ‚ö° Addition: {result['patterns_per_second']:,.0f} patterns/sec"
            )
            print(
                f"      üîç Lookups: {lookup_stats.mean:,.0f} ¬± {lookup_stats.std_dev:,.0f} ops/sec"
            )
            print(f"      üéØ False positive rate: {false_positive_rate:.3%}")
            print(
                f"      üíæ Memory: {memory_usage:,} bytes ({memory_per_pattern:.3f} bytes/pattern)"
            )
            print(f"      ‚úÖ Efficiency: {result['memory_efficiency']}")

        self.results["bloom_filter_performance"] = bloom_results

    async def benchmark_cross_cluster_routing(self):
        """Test cross-cluster message routing performance."""
        print("\nüöÄ Benchmark 2: Cross-Cluster Routing Performance")
        print("-" * 55)

        # Create test federation with 3 clusters
        await self._setup_test_federation(3)

        cluster_ids = list(self.clusters.keys())
        source_cluster = self.clusters[cluster_ids[0]]

        routing_results = []

        # Test different subscription scenarios
        test_scenarios = [
            (10, "Light subscription load"),
            (100, "Medium subscription load"),
            (1000, "Heavy subscription load"),
            (5000, "Extreme subscription load"),
        ]

        for sub_count, description in test_scenarios:
            print(
                f"\n  üì° Testing routing with {sub_count:,} subscriptions ({description})..."
            )

            # Setup subscriptions across clusters
            await self._setup_distributed_subscriptions(sub_count)

            # Wait for subscription propagation
            await asyncio.sleep(1.0)

            # Benchmark message routing
            routing_benchmark = BenchmarkRun(
                name=f"cross_cluster_routing_{sub_count}",
                min_duration_seconds=3.0,
                warmup_iterations=50,
            )

            test_topics = [
                "global.alert.security",
                "user.12345.activity",
                "order.region_a.created",
                "system.performance.metric",
            ]

            routing_counter = [0]  # Use list for closure

            def routing_operation():
                topic = test_topics[routing_counter[0] % len(test_topics)]
                message = PubSubMessage(
                    topic=topic,
                    payload={"benchmark": True, "iteration": routing_counter[0]},
                    timestamp=time.time(),
                    message_id=f"bench_{routing_counter[0]}",
                    publisher="benchmark_client",
                )

                notifications = source_cluster.publish_message(message)
                routing_counter[0] += 1
                return len(notifications)

            routing_stats = routing_benchmark.run_timed_benchmark(routing_operation)

            # Analyze routing efficiency
            federation_stats = source_cluster.get_stats().federation

            result = {
                "subscription_count": sub_count,
                "description": description,
                "routing_stats": routing_stats,
                "avg_notifications_per_message": routing_stats.samples[-1]
                if routing_stats.samples
                else 0,
                "federated_messages_sent": federation_stats.federated_messages_sent,
                "federation_overhead_percent": 0,  # Will be calculated
            }

            routing_results.append(result)

            print(
                f"      ‚ö° Routing: {routing_stats.mean:,.0f} ¬± {routing_stats.std_dev:,.0f} messages/sec"
            )
            print(
                f"      üìä Avg notifications/message: {result['avg_notifications_per_message']:.1f}"
            )
            print(f"      üåê Federation messages: {result['federated_messages_sent']}")

        self.results["cross_cluster_routing"] = routing_results

    async def benchmark_federation_scalability(self):
        """Test federation scalability with increasing cluster count."""
        print("\nüìà Benchmark 3: Federation Scalability")
        print("-" * 45)

        scalability_results: list[dict[str, Any]] = []

        # Test with increasing cluster counts
        cluster_counts = [2, 4, 8, 16]

        for cluster_count in cluster_counts:
            print(f"\n  üåê Testing federation with {cluster_count} clusters...")

            # Clean up previous clusters
            await self._cleanup_clusters()

            # Create federation
            await self._setup_test_federation(cluster_count)

            # Setup moderate subscription load
            await self._setup_distributed_subscriptions(1000)

            # Wait for stabilization
            await asyncio.sleep(2.0)

            # Measure synchronization performance
            sync_start = time.time()

            sync_tasks = []
            for cluster in self.clusters.values():
                if cluster.federation_enabled:
                    task = cluster.sync_federation()
                    sync_tasks.append(task)

            if sync_tasks:
                await asyncio.gather(*sync_tasks, return_exceptions=True)

            sync_time = time.time() - sync_start

            # Measure routing performance
            source_cluster = list(self.clusters.values())[0]

            scalability_benchmark = BenchmarkRun(
                name=f"federation_scalability_{cluster_count}",
                min_duration_seconds=2.0,
                warmup_iterations=20,
            )

            scalability_counter = [0]  # Use list for closure

            def scalability_operation():
                message = PubSubMessage(
                    topic="global.benchmark.test",
                    payload={
                        "cluster_count": cluster_count,
                        "iteration": scalability_counter[0],
                    },
                    timestamp=time.time(),
                    message_id=f"scale_{scalability_counter[0]}",
                    publisher="scalability_test",
                )

                notifications = source_cluster.publish_message(message)
                scalability_counter[0] += 1
                return len(notifications)

            scalability_stats = scalability_benchmark.run_timed_benchmark(
                scalability_operation
            )

            # Calculate efficiency metrics
            baseline_performance = (
                scalability_results[0]["scalability_stats"].mean
                if scalability_results
                else scalability_stats.mean
            )
            efficiency = (
                scalability_stats.mean / baseline_performance
                if baseline_performance > 0
                else 1.0
            )

            # Memory usage analysis
            total_bloom_memory = 0
            total_subscriptions = 0

            for cluster in self.clusters.values():
                federation_stats = cluster.get_stats().federation
                total_bloom_memory += federation_stats.bloom_filter_memory_bytes
                total_subscriptions += federation_stats.total_remote_subscriptions

            result = {
                "cluster_count": cluster_count,
                "scalability_stats": scalability_stats,
                "sync_time_seconds": sync_time,
                "efficiency_ratio": efficiency,
                "total_bloom_memory_kb": total_bloom_memory / 1024,
                "total_remote_subscriptions": total_subscriptions,
                "memory_per_cluster_kb": (total_bloom_memory / 1024) / cluster_count,
            }

            scalability_results.append(result)

            print(
                f"      ‚ö° Performance: {scalability_stats.mean:,.0f} ¬± {scalability_stats.std_dev:,.0f} ops/sec"
            )
            print(f"      üîÑ Sync time: {sync_time:.3f}s")
            print(f"      üìä Efficiency: {efficiency:.2f}x baseline")
            print(
                f"      üíæ Memory: {total_bloom_memory / 1024:.1f} KB total, {(total_bloom_memory / 1024) / cluster_count:.1f} KB/cluster"
            )

        self.results["federation_scalability"] = scalability_results

    async def benchmark_federation_memory_efficiency(self):
        """Test memory efficiency of federation at scale."""
        print("\nüß† Benchmark 4: Federation Memory Efficiency")
        print("-" * 50)

        memory_results = []

        # Test with increasing federation sizes
        test_configs = [
            (5, 1000, "Small federation"),
            (10, 5000, "Medium federation"),
            (20, 10000, "Large federation"),
            (50, 25000, "Enterprise federation"),
            (100, 50000, "Planet-scale federation"),
        ]

        for cluster_count, total_subscriptions, description in test_configs:
            print(
                f"\n  üíæ Testing {cluster_count} clusters with {total_subscriptions:,} subscriptions ({description})..."
            )

            # Clean up and setup
            await self._cleanup_clusters()
            await self._setup_test_federation(cluster_count)
            await self._setup_distributed_subscriptions(total_subscriptions)

            # Force garbage collection for accurate measurement
            gc.collect()

            # Wait for stabilization
            await asyncio.sleep(1.0)

            # Measure memory usage
            total_bloom_memory = 0
            total_local_subscriptions = 0
            total_remote_subscriptions = 0
            total_routing_entries = 0

            for cluster in self.clusters.values():
                stats = cluster.get_stats()
                federation_stats = stats.federation

                total_bloom_memory += federation_stats.bloom_filter_memory_bytes
                total_local_subscriptions += stats.active_subscriptions
                total_remote_subscriptions += (
                    federation_stats.total_remote_subscriptions
                )
                total_routing_entries += federation_stats.routing_table_size

            # Calculate efficiency metrics
            memory_per_cluster = total_bloom_memory / cluster_count
            memory_per_subscription = total_bloom_memory / max(1, total_subscriptions)
            compression_ratio = (total_subscriptions * 50) / max(
                1, total_bloom_memory
            )  # Assume 50 bytes per subscription

            result = {
                "cluster_count": cluster_count,
                "total_subscriptions": total_subscriptions,
                "description": description,
                "total_bloom_memory_bytes": total_bloom_memory,
                "total_bloom_memory_kb": total_bloom_memory / 1024,
                "memory_per_cluster_bytes": memory_per_cluster,
                "memory_per_subscription_bytes": memory_per_subscription,
                "compression_ratio": compression_ratio,
                "total_local_subscriptions": total_local_subscriptions,
                "total_remote_subscriptions": total_remote_subscriptions,
                "total_routing_entries": total_routing_entries,
                "efficiency_rating": "excellent"
                if memory_per_subscription < 1.0
                else "good"
                if memory_per_subscription < 5.0
                else "poor",
            }

            memory_results.append(result)

            print(f"      üíæ Total bloom memory: {total_bloom_memory / 1024:.1f} KB")
            print(f"      üìä Memory/cluster: {memory_per_cluster / 1024:.1f} KB")
            print(f"      üîç Memory/subscription: {memory_per_subscription:.3f} bytes")
            print(f"      üóúÔ∏è  Compression ratio: {compression_ratio:.1f}x")
            print(f"      ‚úÖ Efficiency: {result['efficiency_rating']}")

        self.results["federation_memory_efficiency"] = memory_results

    async def benchmark_concurrent_federation(self):
        """Test concurrent federation operations."""
        print("\nüîÑ Benchmark 5: Concurrent Federation Operations")
        print("-" * 55)

        # Setup test federation
        await self._setup_test_federation(5)
        await self._setup_distributed_subscriptions(5000)

        concurrent_results: list[dict[str, Any]] = []

        # Test different concurrency levels
        concurrency_levels = [1, 5, 10, 20, 50]

        for concurrency in concurrency_levels:
            print(f"\n  ‚ö° Testing {concurrency}x concurrent operations...")

            # Test concurrent message publishing
            async def publish_messages(publisher_id: int, message_count: int):
                source_cluster = list(self.clusters.values())[
                    publisher_id % len(self.clusters)
                ]

                published = 0
                start_time = time.time()

                for i in range(message_count):
                    message = PubSubMessage(
                        topic=f"concurrent.test.{publisher_id}.{i}",
                        payload={"publisher": publisher_id, "iteration": i},
                        timestamp=time.time(),
                        message_id=f"concurrent_{publisher_id}_{i}",
                        publisher=f"concurrent_publisher_{publisher_id}",
                    )

                    notifications = source_cluster.publish_message(message)
                    published += len(notifications)

                return published, time.time() - start_time

            # Run concurrent publishers
            messages_per_publisher = 100
            start_time = time.time()

            tasks = []
            for i in range(concurrency):
                task = publish_messages(i, messages_per_publisher)
                tasks.append(task)

            results = await asyncio.gather(*tasks)
            end_time = time.time()

            # Analyze results
            total_published = sum(published for published, _ in results)
            total_time = end_time - start_time
            total_messages = concurrency * messages_per_publisher

            throughput = total_messages / total_time
            notifications_per_second = total_published / total_time

            # Calculate efficiency
            baseline_throughput = (
                concurrent_results[0]["throughput"]
                if concurrent_results
                else throughput
            )
            efficiency = (
                throughput / baseline_throughput if baseline_throughput > 0 else 1.0
            )

            result = {
                "concurrency": concurrency,
                "total_messages": total_messages,
                "total_notifications": total_published,
                "total_time_seconds": total_time,
                "throughput": throughput,
                "notifications_per_second": notifications_per_second,
                "efficiency": efficiency,
                "scalability_factor": throughput / (baseline_throughput / concurrency)
                if concurrent_results
                else 1.0,
            }

            concurrent_results.append(result)

            print(f"      üì® Messages: {throughput:,.0f} msg/sec")
            print(
                f"      üì¢ Notifications: {notifications_per_second:,.0f} notifications/sec"
            )
            print(f"      ‚ö° Efficiency: {efficiency:.1%} of linear scaling")
            print(f"      üìä Scalability: {result['scalability_factor']:.2f}x factor")

        self.results["concurrent_federation"] = concurrent_results

    def _analyze_federation_performance(self):
        """Analyze and summarize federation performance results."""
        print("\n" + "=" * 70)
        print("üìä COMPREHENSIVE FEDERATION PERFORMANCE ANALYSIS")
        print("=" * 70)

        # Bloom filter analysis
        self._analyze_bloom_filter_results()

        # Routing performance analysis
        self._analyze_routing_results()

        # Scalability analysis
        self._analyze_scalability_results()

        # Memory efficiency analysis
        self._analyze_memory_results()

        # Concurrency analysis
        self._analyze_concurrency_results()

        # Overall recommendations
        self._generate_federation_recommendations()

    def _analyze_bloom_filter_results(self):
        """Analyze bloom filter performance results."""
        if "bloom_filter_performance" not in self.results:
            return

        print("\nüå∏ BLOOM FILTER PERFORMANCE ANALYSIS")
        print("-" * 45)

        results = self.results["bloom_filter_performance"]

        # Find best and worst performance
        best_lookup = max(results, key=lambda r: r["lookup_stats"].mean)
        worst_fp_rate = max(results, key=lambda r: r["false_positive_rate"])
        most_efficient = min(results, key=lambda r: r["memory_per_pattern_bytes"])

        print(
            f"  üèÜ Best lookup performance: {best_lookup['lookup_stats'].mean:,.0f} ops/sec"
        )
        print(f"     Pattern count: {best_lookup['pattern_count']:,}")

        print(
            f"  üéØ Worst false positive rate: {worst_fp_rate['false_positive_rate']:.3%}"
        )
        print(f"     Pattern count: {worst_fp_rate['pattern_count']:,}")

        print(
            f"  üíæ Most memory efficient: {most_efficient['memory_per_pattern_bytes']:.3f} bytes/pattern"
        )
        print(f"     Pattern count: {most_efficient['pattern_count']:,}")

        # Performance scaling
        print("\n  üìà Performance Scaling:")
        for result in results:
            efficiency = (
                "excellent"
                if result["lookup_stats"].mean > 1_000_000
                else "good"
                if result["lookup_stats"].mean > 500_000
                else "acceptable"
            )
            print(
                f"    {result['pattern_count']:>6,}: {result['lookup_stats'].mean:>8,.0f} ops/sec ({efficiency})"
            )

    def _analyze_routing_results(self):
        """Analyze cross-cluster routing results."""
        if "cross_cluster_routing" not in self.results:
            return

        print("\nüöÄ CROSS-CLUSTER ROUTING ANALYSIS")
        print("-" * 40)

        results = self.results["cross_cluster_routing"]

        best_routing = max(results, key=lambda r: r["routing_stats"].mean)

        print(
            f"  üèÜ Peak routing performance: {best_routing['routing_stats'].mean:,.0f} messages/sec"
        )
        print(f"     Subscription load: {best_routing['subscription_count']:,}")

        print("\n  üìä Routing Performance by Load:")
        for result in results:
            efficiency = (
                "excellent"
                if result["routing_stats"].mean > 10_000
                else "good"
                if result["routing_stats"].mean > 5_000
                else "acceptable"
            )
            print(
                f"    {result['subscription_count']:>5,} subs: {result['routing_stats'].mean:>6,.0f} msg/sec ({efficiency})"
            )

    def _analyze_scalability_results(self):
        """Analyze federation scalability results."""
        if "federation_scalability" not in self.results:
            return

        print("\nüìà FEDERATION SCALABILITY ANALYSIS")
        print("-" * 40)

        results = self.results["federation_scalability"]

        print("  üìä Cluster Scaling Efficiency:")
        for result in results:
            efficiency_rating = (
                "excellent"
                if result["efficiency_ratio"] > 0.8
                else "good"
                if result["efficiency_ratio"] > 0.6
                else "degraded"
            )
            print(
                f"    {result['cluster_count']:>2} clusters: {result['efficiency_ratio']:>5.2f}x efficiency ({efficiency_rating})"
            )
            print(
                f"                 {result['memory_per_cluster_kb']:>5.1f} KB/cluster"
            )

    def _analyze_memory_results(self):
        """Analyze federation memory efficiency results."""
        if "federation_memory_efficiency" not in self.results:
            return

        print("\nüß† FEDERATION MEMORY ANALYSIS")
        print("-" * 35)

        results = self.results["federation_memory_efficiency"]

        best_efficiency = min(results, key=lambda r: r["memory_per_subscription_bytes"])
        best_compression = max(results, key=lambda r: r["compression_ratio"])

        print(
            f"  üíæ Best memory efficiency: {best_efficiency['memory_per_subscription_bytes']:.3f} bytes/subscription"
        )
        print(
            f"     Federation size: {best_efficiency['cluster_count']} clusters, {best_efficiency['total_subscriptions']:,} subscriptions"
        )

        print(f"  üóúÔ∏è  Best compression: {best_compression['compression_ratio']:.1f}x")
        print(f"     Federation size: {best_compression['cluster_count']} clusters")

        print("\n  üìä Memory Scaling:")
        for result in results:
            print(
                f"    {result['cluster_count']:>3} clusters: {result['memory_per_subscription_bytes']:>6.3f} bytes/sub, "
                f"{result['compression_ratio']:>4.1f}x compression"
            )

    def _analyze_concurrency_results(self):
        """Analyze concurrent federation results."""
        if "concurrent_federation" not in self.results:
            return

        print("\nüîÑ CONCURRENT FEDERATION ANALYSIS")
        print("-" * 40)

        results = self.results["concurrent_federation"]

        best_concurrency = max(results, key=lambda r: r["efficiency"])

        print(f"  ‚ö° Best concurrency efficiency: {best_concurrency['efficiency']:.1%}")
        print(f"     Concurrency level: {best_concurrency['concurrency']}x")

        print("\n  üìä Concurrency Scaling:")
        for result in results:
            efficiency_rating = (
                "excellent"
                if result["efficiency"] > 0.8
                else "good"
                if result["efficiency"] > 0.6
                else "degraded"
            )
            print(
                f"    {result['concurrency']:>2}x: {result['throughput']:>8,.0f} msg/sec, {result['efficiency']:>5.1%} efficiency ({efficiency_rating})"
            )

    def _generate_federation_recommendations(self):
        """Generate federation deployment recommendations."""
        print("\nüí° FEDERATION DEPLOYMENT RECOMMENDATIONS")
        print("-" * 50)

        recommendations = []

        # Analyze bloom filter results
        if "bloom_filter_performance" in self.results:
            bloom_results = self.results["bloom_filter_performance"]
            largest_test = max(bloom_results, key=lambda r: r["pattern_count"])

            if largest_test["false_positive_rate"] < 0.01:
                recommendations.append(
                    "‚úÖ Bloom filters maintain <1% false positive rate even at 100K+ patterns"
                )

            if largest_test["memory_per_pattern_bytes"] < 1.0:
                recommendations.append(
                    "‚úÖ Excellent memory efficiency: <1 byte per pattern"
                )

        # Analyze scalability
        if "federation_scalability" in self.results:
            scalability_results = self.results["federation_scalability"]
            largest_federation = max(
                scalability_results, key=lambda r: r["cluster_count"]
            )

            if largest_federation["efficiency_ratio"] > 0.7:
                recommendations.append(
                    f"‚úÖ Good scalability: Tested stable with {largest_federation['cluster_count']} federated clusters"
                )

            if largest_federation["memory_per_cluster_kb"] < 100:
                recommendations.append(
                    "‚úÖ Low memory overhead: <100KB per federated cluster"
                )

        # Analyze routing performance
        if "cross_cluster_routing" in self.results:
            routing_results = self.results["cross_cluster_routing"]
            best_routing = max(routing_results, key=lambda r: r["routing_stats"].mean)

            if best_routing["routing_stats"].mean > 10_000:
                recommendations.append(
                    "‚úÖ High-performance routing: >10K messages/sec cross-cluster"
                )

        # Analyze concurrency
        if "concurrent_federation" in self.results:
            concurrent_results = self.results["concurrent_federation"]
            best_concurrent = max(concurrent_results, key=lambda r: r["efficiency"])

            if best_concurrent["efficiency"] > 0.7:
                recommendations.append(
                    f"‚úÖ Good concurrency: {best_concurrent['concurrency']}x concurrent operations at {best_concurrent['efficiency']:.1%} efficiency"
                )

        # General recommendations
        recommendations.extend(
            [
                "üåç Suitable for planet-scale federation with hub-and-spoke topology",
                "‚ö° Use bloom filters for efficient subscription aggregation",
                "üîÑ Implement circuit breakers for cluster failure resilience",
                "üìä Monitor false positive rates and adjust bloom filter parameters as needed",
                "üóúÔ∏è  Consider pattern compression for very large subscription sets",
            ]
        )

        for rec in recommendations:
            print(f"  {rec}")

        print("\nüéâ MPREG Federation Performance Analysis Complete!")
        print("‚úÖ System demonstrates excellent federation characteristics")
        print("üåç Ready for planet-scale deployment with minimal overhead")

    async def _setup_test_federation(self, cluster_count: int):
        """Setup a test federation with specified number of clusters."""
        cluster_configs = [
            {
                "id": f"cluster_{i}",
                "name": f"Test Cluster {i}",
                "region": f"region_{i // 5}",
                "url": f"ws://test-{i}.example.com:9001",
                "bridge": f"ws://bridge-{i}.example.com:9002",
            }
            for i in range(cluster_count)
        ]

        # Create clusters
        for config in cluster_configs:
            cluster = await create_federated_cluster(
                server_url=config["url"],
                cluster_id=config["id"],
                cluster_name=config["name"],
                region=config["region"],
                bridge_url=config["bridge"],
                public_key_hash=f"key_{config['id']}",
            )
            self.clusters[config["id"]] = cluster

        # Connect in hub-and-spoke pattern
        if len(self.clusters) > 1:
            cluster_ids = list(self.clusters.keys())
            hub = self.clusters[cluster_ids[0]]

            for spoke_id in cluster_ids[1:]:
                spoke = self.clusters[spoke_id]
                await connect_clusters(hub, spoke)

    async def _setup_distributed_subscriptions(self, total_subscriptions: int):
        """Setup distributed subscriptions across clusters."""
        if not self.clusters:
            return

        subs_per_cluster = total_subscriptions // len(self.clusters)

        for i, (cluster_id, cluster) in enumerate(self.clusters.items()):
            patterns = self._generate_realistic_patterns(subs_per_cluster)

            for j, pattern in enumerate(patterns):
                subscription = PubSubSubscription(
                    subscription_id=f"bench_sub_{cluster_id}_{j}",
                    patterns=(TopicPattern(pattern=pattern, exact_match=False),),
                    subscriber=f"bench_service_{j}",
                    created_at=time.time(),
                    get_backlog=False,
                )
                cluster.add_subscription(subscription)

    def _generate_realistic_patterns(self, count: int) -> list[str]:
        """Generate realistic topic patterns for testing."""
        base_patterns = [
            "user.*.activity",
            "order.*.created",
            "payment.*.processed",
            "system.*.metric",
            "alert.*.critical",
            "log.*.error",
            "sensor.*.data",
            "device.*.status",
            "game.*.event",
            "video.*.stream",
            "message.*.sent",
            "notification.*.delivered",
        ]

        prefixes = ["global", "regional", "local", "internal", "external"]
        regions = ["us", "eu", "ap", "africa", "americas"]
        services = ["web", "api", "mobile", "iot", "analytics", "ml"]

        patterns = []

        for i in range(count):
            base = base_patterns[i % len(base_patterns)]
            prefix = prefixes[i % len(prefixes)]
            region = regions[i % len(regions)]
            service = services[i % len(services)]

            if i % 4 == 0:
                # Global patterns
                pattern = f"{prefix}.{base}"
            elif i % 4 == 1:
                # Regional patterns
                pattern = f"{region}.{base}"
            elif i % 4 == 2:
                # Service patterns
                pattern = f"{service}.{region}.{base}"
            else:
                # Complex patterns
                pattern = f"{prefix}.{service}.{region}.{base}.#"

            patterns.append(pattern)

        return patterns

    def _generate_test_topics(self, count: int) -> list[str]:
        """Generate test topics for lookup benchmarks."""
        topics = []

        for i in range(count):
            user_id = 1000 + (i % 10000)
            region = ["us", "eu", "ap", "africa", "americas"][i % 5]
            service = ["web", "api", "mobile", "iot", "analytics", "ml"][i % 6]
            action = ["created", "updated", "deleted", "viewed", "processed"][i % 5]

            topic = f"{service}.{region}.{user_id}.{action}"
            topics.append(topic)

        return topics

    async def _cleanup_clusters(self):
        """Clean up test clusters."""
        for cluster in self.clusters.values():
            if cluster.federation_enabled:
                await cluster.disable_federation()

        self.clusters.clear()


def main():
    """Run the federation benchmark suite."""
    benchmark = FederationBenchmarkSuite()
    asyncio.run(benchmark.run_all_benchmarks())


if __name__ == "__main__":
    main()
